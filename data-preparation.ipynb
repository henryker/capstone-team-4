{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport polars as pl\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-13T20:45:03.566723Z","iopub.execute_input":"2024-03-13T20:45:03.567091Z","iopub.status.idle":"2024-03-13T20:45:03.882920Z","shell.execute_reply.started":"2024-03-13T20:45:03.567061Z","shell.execute_reply":"2024-03-13T20:45:03.881302Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation Notebook\n\nThis notebook loads the data, performs feature selection and engineering, and joins the tables. The end result is a Train/Val/Test split, to be used for any model training.","metadata":{}},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"# from their starter notebook; preserved for reference\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input/home-credit-credit-risk-model-stability'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-13T20:25:44.809713Z","iopub.execute_input":"2024-03-13T20:25:44.810042Z","iopub.status.idle":"2024-03-13T20:25:44.815960Z","shell.execute_reply.started":"2024-03-13T20:25:44.810014Z","shell.execute_reply":"2024-03-13T20:25:44.814734Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"dataPath = \"/kaggle/input/home-credit-credit-risk-model-stability/\"","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:48:07.392352Z","iopub.execute_input":"2024-03-13T19:48:07.392728Z","iopub.status.idle":"2024-03-13T19:48:18.520160Z","shell.execute_reply.started":"2024-03-13T19:48:07.392699Z","shell.execute_reply":"2024-03-13T19:48:18.518672Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"A couple notes on data interpretation:\n\nWhere predictors were transformed, columns describing the transformation have been added with a capital letter suffixing the predictor name\n* P - Transform DPD (Days past due)\n* M - Masking categories\n* A - Transform amount\n* D - Transform date\n* T - Unspecified Transform\n* L - Unspecified Transform\n\nOn depths: depth of a table refers to how many num_group# columns are used to index. Each case_id is only featured once for each unique set of indices, although it may not have a listing for every set. The indexing is not necessarily chronological either; dates where num_group1 == 2 may be earlier than dates where num_group1 == 0. It may be useful to pull summary information for each case_id, e.g. min, max, median, fraction_empty.","metadata":{}},{"cell_type":"code","source":"# # for exploration purposes: this gives more information about each feature\nfeature_definitions = pl.read_csv(dataPath + \"feature_definitions.csv\")\nprint(feature_definitions.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:30:41.360087Z","iopub.execute_input":"2024-03-13T20:30:41.360459Z","iopub.status.idle":"2024-03-13T20:30:41.370127Z","shell.execute_reply.started":"2024-03-13T20:30:41.360431Z","shell.execute_reply":"2024-03-13T20:30:41.368552Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"shape: (5, 2)\n┌─────────────────────────┬───────────────────────────────────┐\n│ Variable                ┆ Description                       │\n│ ---                     ┆ ---                               │\n│ str                     ┆ str                               │\n╞═════════════════════════╪═══════════════════════════════════╡\n│ actualdpd_943P          ┆ Days Past Due (DPD) of previous … │\n│ actualdpdtolerance_344P ┆ DPD of client with tolerance.     │\n│ addres_district_368M    ┆ District of the person's address… │\n│ addres_role_871L        ┆ Role of person's address.         │\n│ addres_zip_823M         ┆ Zip code of the address.          │\n└─────────────────────────┴───────────────────────────────────┘\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"# helper function from their starter notebook\ndef set_table_dtypes(df: pl.DataFrame) -> pl.DataFrame:\n    # implement here all desired dtypes for tables\n    # the following is just an example\n    for col in df.columns:\n        # last letter of column name will help you determine the type\n        if col[-1] in (\"P\", \"A\"):\n            df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:48:01.635313Z","iopub.execute_input":"2024-03-13T19:48:01.635705Z","iopub.status.idle":"2024-03-13T19:48:01.646411Z","shell.execute_reply.started":"2024-03-13T19:48:01.635674Z","shell.execute_reply":"2024-03-13T19:48:01.644108Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Dataset descriptions\nNote that each train file has an associated test file (files may have been partitioned if too large)\n### DEPTH=0\n* train_base: links case_id to WEEK_NUM and target\n* train_static: contains transaction history for each case_id (late payments, total debt, etc)\n* train_static_cb: data from an external source: demographic data, risk assessment, number of credit checks\n\n\n### DEPTH=1\n* train_person_1: contains internal demographic information: zip code, marital status, gender etc (all hashed)\n\n### DEPTH=2\n* train_credit_bureau_b_2: historical data from an external source, num and value of overdue payments","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:48:07.392352Z","iopub.execute_input":"2024-03-13T19:48:07.392728Z","iopub.status.idle":"2024-03-13T19:48:18.520160Z","shell.execute_reply.started":"2024-03-13T19:48:07.392699Z","shell.execute_reply":"2024-03-13T19:48:18.518672Z"}}},{"cell_type":"code","source":"# load train datasets\ntrain_base = pl.read_csv(dataPath + \"csv_files/train/train_base.csv\")\ntrain_static = pl.concat(\n    [\n        pl.read_csv(dataPath + \"csv_files/train/train_static_0_0.csv\").pipe(set_table_dtypes),\n        pl.read_csv(dataPath + \"csv_files/train/train_static_0_1.csv\").pipe(set_table_dtypes),\n    ],\n    how=\"vertical_relaxed\",\n)\ntrain_static_cb = pl.read_csv(dataPath + \"csv_files/train/train_static_cb_0.csv\").pipe(set_table_dtypes)\ntrain_person_1 = pl.read_csv(dataPath + \"csv_files/train/train_person_1.csv\").pipe(set_table_dtypes) \ntrain_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/train/train_credit_bureau_b_2.csv\").pipe(set_table_dtypes) ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:48:07.392352Z","iopub.execute_input":"2024-03-13T19:48:07.392728Z","iopub.status.idle":"2024-03-13T19:48:18.520160Z","shell.execute_reply.started":"2024-03-13T19:48:07.392699Z","shell.execute_reply":"2024-03-13T19:48:18.518672Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# load test datasets\ntest_basetable = pl.read_csv(dataPath + \"csv_files/test/test_base.csv\")\ntest_static = pl.concat(\n    [\n        pl.read_csv(dataPath + \"csv_files/test/test_static_0_0.csv\").pipe(set_table_dtypes),\n        pl.read_csv(dataPath + \"csv_files/test/test_static_0_1.csv\").pipe(set_table_dtypes),\n        pl.read_csv(dataPath + \"csv_files/test/test_static_0_2.csv\").pipe(set_table_dtypes),\n    ],\n    how=\"vertical_relaxed\",\n)\ntest_static_cb = pl.read_csv(dataPath + \"csv_files/test/test_static_cb_0.csv\").pipe(set_table_dtypes)\ntest_person_1 = pl.read_csv(dataPath + \"csv_files/test/test_person_1.csv\").pipe(set_table_dtypes) \ntest_credit_bureau_b_2 = pl.read_csv(dataPath + \"csv_files/test/test_credit_bureau_b_2.csv\").pipe(set_table_dtypes) ","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:37:18.623556Z","iopub.execute_input":"2024-03-13T20:37:18.624166Z","iopub.status.idle":"2024-03-13T20:37:18.639087Z","shell.execute_reply.started":"2024-03-13T20:37:18.624133Z","shell.execute_reply":"2024-03-13T20:37:18.637839Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"shape: (5, 4)\n┌─────────┬───────────────┬────────┬──────────┐\n│ case_id ┆ date_decision ┆ MONTH  ┆ WEEK_NUM │\n│ ---     ┆ ---           ┆ ---    ┆ ---      │\n│ i64     ┆ str           ┆ i64    ┆ i64      │\n╞═════════╪═══════════════╪════════╪══════════╡\n│ 57543   ┆ 2021-05-14    ┆ 202201 ┆ 100      │\n│ 57549   ┆ 2022-01-17    ┆ 202201 ┆ 100      │\n│ 57551   ┆ 2020-11-27    ┆ 202201 ┆ 100      │\n│ 57552   ┆ 2020-11-27    ┆ 202201 ┆ 100      │\n│ 57569   ┆ 2021-12-20    ┆ 202201 ┆ 100      │\n└─────────┴───────────────┴────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>case_id</th><th>date_decision</th><th>MONTH</th><th>WEEK_NUM</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>57543</td><td>&quot;2021-05-14&quot;</td><td>202201</td><td>100</td></tr><tr><td>57549</td><td>&quot;2022-01-17&quot;</td><td>202201</td><td>100</td></tr><tr><td>57551</td><td>&quot;2020-11-27&quot;</td><td>202201</td><td>100</td></tr><tr><td>57552</td><td>&quot;2020-11-27&quot;</td><td>202201</td><td>100</td></tr><tr><td>57569</td><td>&quot;2021-12-20&quot;</td><td>202201</td><td>100</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"# helper function from their starter notebook\n\ndef convert_strings(df: pd.DataFrame) -> pd.DataFrame:\n    for col in df.columns:  \n        if df[col].dtype.name in ['object', 'string']:\n            df[col] = df[col].astype(\"string\").astype('category')\n            current_categories = df[col].cat.categories\n            new_categories = current_categories.to_list() + [\"Unknown\"]\n            new_dtype = pd.CategoricalDtype(categories=new_categories, ordered=True)\n            df[col] = df[col].astype(new_dtype)\n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform train data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform test data","metadata":{},"execution_count":null,"outputs":[]}]}